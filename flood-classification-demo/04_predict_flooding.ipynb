{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 04-predict-flooding\n",
        "\n",
        "Generate flood and permanent water extent predictions using a pre-trained UNet model."
      ],
      "metadata": {
        "id": "Zrb6r95lOHUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "XrUew3Uc5wSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TQk6YOPisVKg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import rasterio\n",
        "from rasterio import windows\n",
        "from rasterio import features\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GpBiLLvcsXtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get trained UNet flood segmentation model\n",
        "gdrive_folder_base = os.path.join(os.getcwd(), \"drive\", \"MyDrive\")\n",
        "checkpoint_fname = os.path.join(gdrive_folder_base, \"ccai-public\", \"checkpoints_unet_gt3classes_edge_weighted_ce_dice_loss\", \"starfm_preds_batchsize_32_lr_0.001.h5\")"
      ],
      "metadata": {
        "id": "txCoaX6-SHCT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_loss_edge_weight_ce_multiclass(\n",
        "    edge_weight: int,\n",
        "    is_logits: bool,\n",
        "    num_classes: int\n",
        "    ):\n",
        "    \"\"\"dice_loss_edge_weight_ce_multiclass\n",
        "\n",
        "    Edge weighted mutliclass cross entropy loss and dice loss.\n",
        "\n",
        "    Based on Garg et al: https://arxiv.org/pdf/2302.08180.pdf\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    edge_weight : int\n",
        "        Weight value for edges in true mask.\n",
        "    is_logits : bool\n",
        "        Whether values in `y_pred` are logits or probabilities.\n",
        "    num_classes : int\n",
        "         Number of possible classes in segmented image outputs.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Callable\n",
        "        Loss function that can be passed into `model.compile()`\n",
        "        with Keras or Tensorflow.\n",
        "    \"\"\"\n",
        "    def loss(y_true, y_pred):\n",
        "\n",
        "        ### EDGE WEIGHTED CE ###\n",
        "\n",
        "        # kernel for erosion and dilation\n",
        "        kernel = tf.zeros((3, 3, 1), dtype=tf.int64)\n",
        "\n",
        "        # dilation\n",
        "        y_true_dil = y_true\n",
        "        y_true_dil = tf.cast(y_true_dil, dtype=tf.int64)\n",
        "        y_true_dil = tf.math.greater(\n",
        "            y_true_dil, tf.constant(0, dtype=tf.int64))\n",
        "        y_true_dil = tf.where(y_true_dil, 1, 0)\n",
        "        y_true_dil = tf.cast(y_true_dil, dtype=tf.int64)\n",
        "        y_comp_dil = tf.nn.dilation2d(\n",
        "            y_true_dil,\n",
        "            filters=kernel,\n",
        "            strides=(1, 1, 1, 1),\n",
        "            padding=\"SAME\",\n",
        "            data_format=\"NHWC\",\n",
        "            dilations=(1, 1, 1, 1)\n",
        "        )\n",
        "        y_dil_edges = y_comp_dil - y_true_dil\n",
        "\n",
        "        # erosion\n",
        "        y_true_er = y_true\n",
        "        y_true_er = tf.cast(y_true_er, dtype=tf.int64)\n",
        "        y_true_er = tf.math.greater(y_true_er, tf.constant(0, dtype=tf.int64))\n",
        "        y_true_er = tf.where(y_true_er, 1, 0)\n",
        "        y_true_er = tf.cast(y_true_er, dtype=tf.int64)\n",
        "        y_comp_er = tf.nn.erosion2d(\n",
        "            y_true_er,\n",
        "            filters=kernel,\n",
        "            strides=(1, 1, 1, 1),\n",
        "            padding=\"SAME\",\n",
        "            data_format=\"NHWC\",\n",
        "            dilations=(1, 1, 1, 1)\n",
        "        )\n",
        "        y_er_edges = y_comp_er - y_true_er\n",
        "\n",
        "        # weights\n",
        "        edges = tf.add(y_dil_edges, y_er_edges)\n",
        "        edges = tf.multiply(edges, edge_weight)\n",
        "        edges = tf.add(edges, 1)\n",
        "\n",
        "        w_tmp = []\n",
        "        for i in range(0, num_classes):\n",
        "            w_tmp.append(edges)\n",
        "\n",
        "        edge_weights = tf.concat(w_tmp, axis=0)\n",
        "        edge_weights = tf.cast(edge_weights, \"float64\")\n",
        "        edge_weights = tf.reshape(edge_weights, [-1])\n",
        "\n",
        "        # weighted CE\n",
        "        if is_logits:\n",
        "            # Apply softmax to predictions if they are logits\n",
        "            # Applies softmax along the last dimension\n",
        "            # assumes predictions are in channels last format\n",
        "            y_pred = tf.cast(y_pred, \"float64\")\n",
        "            y_pred = tf.keras.activations.softmax(y_pred)\n",
        "\n",
        "        # Following Keras source code - valid outputs when computing logs\n",
        "        y_pred = tf.cast(y_pred, \"float64\")\n",
        "        y_pred = tf.clip_by_value(\n",
        "            y_pred, tf.keras.backend.epsilon(), 1-tf.keras.backend.epsilon())\n",
        "\n",
        "        y_true_f = tf.reshape(tf.one_hot(\n",
        "            tf.cast(y_true, \"int32\"), depth=num_classes, axis=-1), [-1])\n",
        "        y_pred_f = tf.reshape(y_pred, [-1])\n",
        "        y_true_f = tf.cast(y_true_f, \"float64\")\n",
        "        y_pred_f = tf.cast(y_pred_f, \"float64\")\n",
        "\n",
        "        wce = y_true_f * tf.math.log(y_pred_f) * edge_weights\n",
        "\n",
        "        wce = tf.reduce_mean(wce)\n",
        "\n",
        "        wce = -wce\n",
        "\n",
        "        ### DICE LOSS ###\n",
        "        intersect = tf.reduce_sum(y_true_f * y_pred_f, axis=-1, keepdims=False)\n",
        "        denom = tf.reduce_sum(y_true_f + y_pred_f, axis=-1, keepdims=False)\n",
        "\n",
        "        dice = 1 - (tf.reduce_mean((2. * intersect) / (denom + 1e-7)))\n",
        "\n",
        "        return dice + wce\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "1fAMzYqlNVZi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TC Yasa\n",
        "\n",
        "Generate predictions of flooding on croplands in Vanua Levu following Tropical Cyclone Yasa in 2020.  "
      ],
      "metadata": {
        "id": "-8KPdE5HZ33f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_folder = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"tc-yasa-aoi2\")"
      ],
      "metadata": {
        "id": "ZO2lL-XnsoyN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(checkpoint_fname, custom_objects={\"loss\": dice_loss_edge_weight_ce_multiclass(3, False, 3)})"
      ],
      "metadata": {
        "id": "j9HnBnQ2KvhT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load inputs for segmenting flood extent\n",
        "inputs_np = np.load(os.path.join(gdrive_folder, \"starfm_preds_cday_0.npy\"))\n",
        "print(f\"shape of inputs: {inputs_np.shape}\")\n",
        "\n",
        "# add batch\n",
        "tf_tmp_inputs = tf.convert_to_tensor(inputs_np, dtype=tf.float32)\n",
        "tf_tmp_inputs = tf.expand_dims(tf_tmp_inputs, 0)\n",
        "\n",
        "preds = model.predict(tf_tmp_inputs)\n",
        "preds = np.squeeze(preds, axis=0)\n",
        "preds_cat = np.argmax(preds, axis=-1)"
      ],
      "metadata": {
        "id": "ceCJyXylK5gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save prediction\n",
        "with rasterio.open(os.path.join(gdrive_folder, \"starfm_synth_ndvi_0_cday_idx_0.tif\")) as ref:\n",
        "    meta = ref.meta\n",
        "\n",
        "with rasterio.open(os.path.join(gdrive_folder, \"flood-mask-tc-yasa-preds-cday-idx-0.tif\"), \"w\", **meta) as src:\n",
        "    src.write(preds_cat.astype(\"int16\"), 1)"
      ],
      "metadata": {
        "id": "PMySCDtQUD1U"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(preds_cat)"
      ],
      "metadata": {
        "id": "3U73JN-7ZXHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load inputs for segmenting flood extent\n",
        "inputs_np = np.load(os.path.join(gdrive_folder, \"starfm_preds_cday_1.npy\"))\n",
        "print(f\"shape of inputs: {inputs_np.shape}\")\n",
        "\n",
        "# add batch\n",
        "tf_tmp_inputs = tf.convert_to_tensor(inputs_np, dtype=tf.float32)\n",
        "tf_tmp_inputs = tf.expand_dims(tf_tmp_inputs, 0)\n",
        "\n",
        "preds = model.predict(tf_tmp_inputs)\n",
        "preds = np.squeeze(preds, axis=0)\n",
        "preds_cat = np.argmax(preds, axis=-1)"
      ],
      "metadata": {
        "id": "lLHfKlItZaMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save prediction\n",
        "with rasterio.open(os.path.join(gdrive_folder, \"starfm_synth_ndvi_0_cday_idx_1.tif\")) as ref:\n",
        "    meta = ref.meta\n",
        "\n",
        "with rasterio.open(os.path.join(gdrive_folder, \"flood-mask-tc-yasa-preds-cday-idx-1.tif\"), \"w\", **meta) as src:\n",
        "    src.write(preds_cat.astype(\"int16\"), 1)"
      ],
      "metadata": {
        "id": "Qr8ENCKJVAjA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(preds_cat)"
      ],
      "metadata": {
        "id": "IAGFkRCRZcn9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}